version: "2.1"
services:

#PROJE 1: datauret ve stream işlemleri için kullanılan kısımlar ve servisler. real time perakende ve bankacilik uygulaması için. 

  stream-nereye-mysql:
    build: 
     context: ./streamnereye
     dockerfile: Dockerfile_streamnereye
    container_name: stream-nereye-mysql
    hostname: stream-nereye-mysql
    environment:
      - NEREYE="mysql"
      - KAFKA_ADRES="kafka:9092"
      - TOPICNAME="TestTopic1"
    links:
      - kafka
      - mysql
    depends_on:
      - kafka
      - mysql
    entrypoint: 
      - bash 
      - -c 
      - |
        echo 'Sana süre veriyorum...'
        sleep 10
        java -cp DataUret.jar Stream1 mysql kafka:9092 TestTopic1
    networks:
      - csp-ce-net

  datauret1:
    build: 
     context: ./DataUretImageYapma
     dockerfile: Dockerfile_dosyauret
    container_name: datauret1
    hostname: datauret1
    environment:
      - ALISVERIS_INTERVAL=1000
      - ALISVERIS_YERI="dukkan_1"
      - KAFKA_ADRES="kafka:9092"
      - TOPICNAME="TestTopic1"
    links:
      - kafka
    depends_on:
      - kafka
    entrypoint: 
      - bash 
      - -c 
      - |
        echo 'Sana süre veriyorum...'
        sleep 10
        java -cp DataUret.jar DataUret 1000 dukkan_1 kafka:9092 TestTopic1
    networks:
      - csp-ce-net

  mysql:
    image: mysql
    container_name: mysql
    hostname: mysql
    ports: 
      - "3306:3306"
      - "33060:33060"
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    networks:
      - csp-ce-net
    environment:
      MYSQL_ROOT_PASSWORD: mmetin
      MYSQL_DATABASE: mmetin
      MYSQL_USER: mmetin
      MYSQL_PASSWORD: mmetin

# user: admin, pass: admin
# grafana çok yer kapladigindan commentledim
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    ports:
      - 3000:3000
    user: "104"
    links: 
      - mysql
    networks:
      - csp-ce-net
    depends_on:
      - mysql

  zeppelin:
    image: bde2020/zeppelin
    container_name: zeppelin
    hostname: zeppelin
    env_file:
      - ./hadoop-hive.env
    ports:
      - 80:8080
    volumes:
      - ./notebook:/opt/zeppelin/notebook
    networks:
      - csp-ce-net
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
    depends_on:
      - "namenode"

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    hostname: namenode
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    networks:
      - csp-ce-net
    env_file:
      - ./hadoop-hive.env
    ports:
      - "50070:50070"
      - "8020:8020"


  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode1
    hostname: datanode1
    volumes:
      - datanode1:/hadoop/dfs/data
    depends_on:
      - namenode
    env_file:
      - ./hadoop-hive.env
    networks:
      - csp-ce-net
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode2
    hostname: datanode2
    volumes:
      - datanode2:/hadoop/dfs/data
    depends_on:
      - namenode
    env_file:
      - ./hadoop-hive.env
    networks:
      - csp-ce-net
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50076:50075"

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode3
    hostname: datanode3
    volumes:
      - datanode3:/hadoop/dfs/data
    depends_on:
      - namenode
    env_file:
      - ./hadoop-hive.env
    networks:
      - csp-ce-net
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50077:50075"


  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    hostname: hive-server
    env_file:
      - ./hadoop-hive.env
    depends_on:
      - hive-metastore
    networks:
      - csp-ce-net
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"


  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    hostname: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    networks:
      - csp-ce-net
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    depends_on:
      - hive-metastore-postgresql
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    hostname: hive-metastore-postgresql
    networks:
      - csp-ce-net
    volumes:
      - ./metastore-postgresql/postgresql/data:/var/lib/postgresql/data
    depends_on:
      - datanode1
      - datanode2
      - datanode3

  spark-master:
    image: bde2020/spark-master:2.4.0-hadoop2.7
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8082:8082"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - csp-ce-net
  spark-worker-1:
    image: bde2020/spark-worker:2.4.0-hadoop2.7
    hostname: spark-worker-1
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8084:8084"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - csp-ce-net


#ubuntum makinasinda : 
#sudo mkdir -p /opt/nifi 
#sudo chown -R 1000:1000 /opt/nifi 

#http://localhost:8080/nifi/
  nifi:
    cap_add:
      - NET_ADMIN # low port bindings
    image: apache/nifi
    container_name: nifi
    hostname: nifi
    ports:
      - "8080:8080/tcp" # HTTP interface
      - "8443:8443/tcp" # HTTPS interface
      - "514:514/tcp" # Syslog
      - "514:514/udp" # Syslog
      - "2055:2055/udp" # NetFlow
    volumes:
      - /opt/nifi/drivers:/opt/nifi/nifi-current/drivers
      - /opt/nifi/certs:/opt/certs
      - nifi-conf:/opt/nifi/nifi-current/conf
    restart: unless-stopped
    environment:
      NIFI_WEB_HTTP_HOST: '0.0.0.0'
      NIFI_WEB_HTTP_PORT: 8080
      NIFI_SENSITIVE_PROPS_KEY: zsffr4esg6yjkle3 
    networks:
      - csp-ce-net
    links:
      - kafka

#Ubuntum makinası üzerinde:
#/etc/security/limits.conf
#elasticsearch  -  nofile  65535
#ulimit -n 65536
#vi /etc/sysctl.conf
#vm.max_map_count=262144
#sudo sysctl -w vm.max_map_count=262144
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    container_name: elasticsearch
    hostname: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - cluster.initial_master_nodes=elasticsearch
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - discovery.seed_hosts=elasticsearch,elasticsearch_node1
    ports:
      - "9200:9200"
      - "9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - csp-ce-net
    volumes:
      - elastic_data:/usr/share/elasticsearch/data

  elasticsearch_node1:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    container_name: elasticsearch_node1
    hostname: elasticsearch_node1
    environment:
      - node.name=elasticsearch_node1
      - cluster.name=es-docker-cluster
      - cluster.initial_master_nodes=elasticsearch
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - discovery.seed_hosts=elasticsearch,elasticsearch_node1
    ports:
      - "9201:9200"
      - "9301:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - csp-ce-net
    volumes:
      - elastic_data_node1:/usr/share/elasticsearch/data


  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.0
    container_name: kibana
    hostname: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - csp-ce-net

#logstash docker da mysql veri aktaramadim. sorun var. 
#bu nedenle commentledim. logstash calismak isteyenler bakabilir. 
  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.0
    container_name: logstash
    hostname: logstash
    ports:
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"
    depends_on:
      - elasticsearch
      - mysql
    networks:
      - csp-ce-net

  hbase-master:
    image: bde2020/hbase-master:1.0.0-hbase1.2.6
    container_name: hbase-master
    hostname: hbase-master
    env_file:
      - ./hbase-distributed-local.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode1:50075 datanode2:50076 datanode3:50076 zookeeper:2181"
    ports:
      - 16010:16010
    depends_on:
      - zookeeper
      - namenode
      - datanode1
      - datanode2
      - datanode3
    networks:
      - csp-ce-net

  hbase-region:
    image: bde2020/hbase-regionserver:1.0.0-hbase1.2.6
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    env_file:
      - ./hbase-distributed-local.env
    environment:
      HBASE_CONF_hbase_regionserver_hostname: hbase-region
      SERVICE_PRECONDITION: "namenode:50070 datanode1:50075 datanode3:50076 datanode3:50076 zookeeper:2181 hbase-master:16010"
    depends_on:
      - hbase-master
    ports:
      - 16030:16030
    networks:
      - csp-ce-net



  cassandra1:
    image: cassandra:3.7
    container_name: cassandra1
    hostname: cassandra1
    mem_limit: 2g
    ports:
      - "9042:9042"
    volumes:
      - "cassandra1:/var/lib/cassandra"
    environment:
      - "CASSANDRA_SEEDS=cassandra1"
      - "CASSANDRA_CLUSTER_NAME=Test Cluster"
      - "CASSANDRA_DC=se1"
      - "CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch"
    networks:
      - csp-ce-net


  cassandra2:
    image: cassandra:3.7
    container_name: cassandra2
    hostname: cassandra2
    mem_limit: 3g
    ports:
      - "9043:9042"
    volumes:
      - "cassandra2:/var/lib/cassandra"
    environment:
      - "CASSANDRA_SEEDS=cassandra1"
      - "CASSANDRA_CLUSTER_NAME=Test Cluster"
      - "CASSANDRA_DC=se1"
      - "CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch"
    depends_on:
      - cassandra1
    networks:
      - csp-ce-net

  cassandra3:
    image: cassandra:3.7
    container_name: cassandra3
    hostname: cassandra3
    mem_limit: 3g
    ports:
      - "9044:9042"
    volumes:
      - "cassandra3:/var/lib/cassandra"
    environment:
      - "CASSANDRA_SEEDS=cassandra1"
      - "CASSANDRA_CLUSTER_NAME=Test Cluster"
      - "CASSANDRA_DC=se1"
      - "CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch"
    depends_on:
      - cassandra1
    networks:
      - csp-ce-net

# PROJE 2: CSP ile ilgili kısımlar ve servisler.
  ssb-sse:
    image: docker.repository.cloudera.com/cloudera/csp-ce/ssb-sse:1.0.0.0
    container_name: ssb-sse
    hostname: ssb-sse
    ports:
      - "18121:18121"
    networks:
      - csp-ce-net
    volumes:
      - ssb-volume:/persistent
    depends_on:
      postgresql:
        condition: service_started
      kafka:
        condition: service_healthy

  ssb-mve:
    image: docker.repository.cloudera.com/cloudera/csp-ce/ssb-mve:1.0.0.0
    container_name: ssb-mve
    hostname: ssb-mve
    ports:
      - "18131:18131"
    networks:
      - csp-ce-net
    restart: on-failure
    depends_on:
      ssb-sse:
        condition: service_started

  postgresql:
    image: docker.repository.cloudera.com/cloudera/csp-ce/postgresql:1.0.0.0
    container_name: postgresql
    hostname: postgresql
    ports:
      - "5432:5432"
    networks:
      - csp-ce-net
    volumes:
      - pg-volume:/var/lib/postgresql

  zookeeper:
    image: docker.repository.cloudera.com/cloudera/csp-ce/zookeeper:1.0.0.0
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    networks:
      - csp-ce-net
    volumes:
      - zk-volume:/data
    healthcheck:
      test: bash -c '/usr/bin/test $$({ printf >&3 "ruok" && /usr/bin/cat <&3; } 3<>/dev/tcp/localhost/2181) == "imok"'
      interval: 30s
      timeout: 10s
      retries: 5
    restart: on-failure

  kafka:
    image: docker.repository.cloudera.com/cloudera/csp-ce/kafka:1.0.0.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
      - "9094:9094"
      - "24042:24042"
      - "9100:9100"
      - "19092:19092"
    networks:
      - csp-ce-net
    volumes:
      - kf-volume:/data
    healthcheck:
      test: [ "CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "localhost:9092" ]
      interval: 5s
      timeout: 10s
      retries: 30
    restart: on-failure
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,CONNECTIONS_FROM_HOST://localhost:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONNECTIONS_FROM_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1


  kafka-connect:
    image: docker.repository.cloudera.com/cloudera/csp-ce/kafka-connect:1.0.0.0
    container_name: kafka-connect
    hostname: kafka-connect
    ports:
      - "28083:28083"
      - "28086:28086"
    networks:
      - csp-ce-net
    volumes:
      - kfc-volume:/data
    restart: on-failure
    healthcheck:
      test: [ "CMD", "curl", "-f", "kafka-connect:28083/connectors" ]
      interval: 5s
      timeout: 10s
      retries: 30
    depends_on:
      kafka:
        condition: service_healthy

  prometheus:
    image: docker.repository.cloudera.com/cloudera/csp-ce/prometheus:1.0.0.0
    container_name: prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    networks:
      - csp-ce-net
    volumes:
      - prom-volume:/persistent
    healthcheck:
      test: [ "CMD", "curl", "-f", "prometheus:9090/api/v1/targets?state=active" ]
      interval: 5s
      timeout: 10s
      retries: 30
    restart: on-failure
    depends_on:
      kafka-connect:
        condition: service_healthy

  schema-registry:
    image: docker.repository.cloudera.com/cloudera/csp-ce/schema-registry:1.0.0.0
    container_name: schema-registry
    hostname: schema-registry
    ports:
      - "7788:7788"
    networks:
      - csp-ce-net
    healthcheck:
      test: [ "CMD", "curl", "-f", "schema-registry:7788/api/v1/schemaregistry/schemas" ]
      interval: 5s
      timeout: 10s
      retries: 50
    restart: on-failure
    volumes:
      - sr-volume:/tmp/registry/local-jars
    depends_on:
      postgresql:
        condition: service_started
      kafka-connect:
        condition: service_healthy

  smm:
    image: docker.repository.cloudera.com/cloudera/csp-ce/smm:1.0.0.0
    container_name: smm
    hostname: smm
    ports:
      - "8585:8585"
      - "9991:9991"
    networks:
      - csp-ce-net
    healthcheck:
      test: [ "CMD", "curl", "-f", "smm-rest:8585/api/v2/admin/metrics/aggregated/topics?duration=LAST_THIRTY_MINUTES&state=all" ]
      interval: 5s
      timeout: 10s
      retries: 30
    restart: on-failure
    depends_on:
      postgresql:
        condition: service_started
      prometheus:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy

  flink-jobmanager:
    image: docker.repository.cloudera.com/cloudera/csp-ce/flink:1.0.0.0
    container_name: flink-jobmanager
    hostname: flink-jobmanager
    ports:
      - "8081:8081"
    entrypoint: /usr/bin/init-flink jobmanager
    networks:
      - csp-ce-net
    volumes:
      - flink-volume:/persistent
    healthcheck:
      test: [ "CMD", "curl", "-f", "localhost:8081" ]
      interval: 5s
      timeout: 10s
      retries: 30

  flink-taskmanager:
    image: docker.repository.cloudera.com/cloudera/csp-ce/flink:1.0.0.0
    container_name: flink-taskmanager
    hostname: flink-taskmanager
    entrypoint: /usr/bin/init-flink taskmanager
    networks:
      - csp-ce-net
    volumes:
      - flink-volume:/persistent
    depends_on:
      flink-jobmanager:
        condition: service_healthy


networks:
  csp-ce-net:
    driver: bridge

volumes:
  ssb-volume:
  flink-volume:
  pg-volume:
  zk-volume:
  kf-volume:
  kfc-volume:
  prom-volume:
  sr-volume:
  db_data: {}
  namenode: {}
  datanode1: {}
  datanode2: {}
  datanode3: {}
  nifi-conf: {}
  elastic_data: {}
  elastic_data_node1: {}
  cassandra1: {}
  cassandra2: {}
  cassandra3: {}
